---
title: "Topic modelling cannot identify immediate changes to research themes in Alzheimer's Disease around the accelerated approval of lecanemab"
author: "Jess Scrimshire"
date: "`r Sys.Date()`"
engine: knitr
execute:
  echo: false
  include: true
  error: false
  message: false
  warning: false
  cache: true
  freeze: true
format:
  html: 
    page-layout: full
    mainfont: Arial
    fontsize: 11px
toc: true
toc-location: left
bibliography: references.bib
csl: university-of-york-vancouver.csl
---

```{r}
#| label: packages
#| include: false
library(rmarkdown)
source("scripts/00_setting_up.R")
```

```{r}
#| label: data
#| include: false
load("updated_project.RData")

abstract_n <- abstract_unigrams_clean %>%
  distinct(title) %>% count() %>% pull(n)
```

|                      | Estimated Words (\~2800) |
|----------------------|--------------------------|
| Introduction         | 873                      |
| Methods              | 775                      |
| Results & Discussion | 1191                     |
| Abstract             | 157                      |

# Abstract

Every year thousands of scientific articles are published concerning the chronic neurodegenerative disorder and leading cause of dementia, Alzheimer’s disease (AD). Currently there are no treatments that cure AD, however recently the anti-amyloid immunotherapy lecanemab has been granted accelerated approval by the FDA. Using text mining and topic modelling, full abstract text between `r format(min(abstract_unigrams_clean$date), "%d-%m-%Y")` and `r format(max(abstract_unigrams_clean$date), "%d-%m-%Y")`, and containing the MeSH term “Alzheimer’s Disease” from PubMed and preprint databases, were allocated to two corpuses determined by the accelerated approval date for lecanemab, 06-01-2023. Despite the frequency of literature increasing concerning terms relating to lecanumab, references to cellular and molecular pathology has remained consistent surrounding its approval. Increasing probabilities for the unigrams, 'tau' and 'placebo' may suggest the research is shifting towards new therapeutic targets and advances in later phase clinical trials, however a longer follow up period will be necessary to draw these conclusions.

# Introduction

## Alzheimer's Disease

Alzheimer’s disease (AD) is a chronic neurodegenerative disease affecting over 55 million people worldwide, and is the most common cause of dementia [@World_Health_Organization2023-eb]. The predominant symptoms of AD usually manifest after the age of 65 and include cognitive impairment, physical and emotional difficulties [@2023_Alzheimers_disease_facts_and_figures2023-ek]. The mechanisms determining the progression of AD are not fully understood, but many agree on the amyloid or tau hypotheses, originating from the presence of amyloid-beta (Aβ) plaques and neurofibrillary tau tangles frequently found in the brains of patients with AD [@Villemagne2013-xk; @Iaccarino2018-ta]. These abnormal proteins lead to disruptions in neuronal signalling pathways and may result in cortical and hippocampal atrophy leading to cognitive decline in AD patients.

AD diagnosis requires the presence of both amyloid and tau pathologies, and signs of neuroinflammation, neuronal death and brain atrophy [@Garcia-Morales2021-zb]. Biomarkers of neuroinflammation can be found in cerebrospinal fluid (CSF) and blood plasma [@Janeiro2021-sg] and brain atrophy can be measured with techniques such as magnetic resonance imaging [@Odusami2021-pp]. Physiological changes in the brain develop before the onset of symptoms which makes it difficult to find treatments when many patients are diagnosed with AD after irreversible neuronal death and hippocampal damage.

AD has multiple risk factors suggesting age, epigentic modifiers, infectious agents, and diet all contribute to the development of AD [@A_Armstrong2019-go; @Henderson1988-cr]. An epidemiological comparison of people aged 65 years and older from two different decades, suggested that the prevalence of AD is decreasing due to the increase in healthcare resources [@Matthews2013-vu].

## Treatments for AD

There are currently no therapies or interventions that can cure AD, but several approved treatments exist to manage cognitive impairment, to alleviate symptoms, and enhance the overall quality of life for patients. Acetylcholinesterase inhibitors (AchE) aim to increase the levels of the neurotransmitter acetylcholine which are attenuated during the pathologies of AD and associated with the loss of cholinergic neurons [@Colovic2013-it]. Whilst AchEs provide many benefits to treat the symptoms of AD, they do not delay or stop the progression of the disease and the effects may only last for 12-24 months [@Courtney2004-br]. Mementine is a NMDA receptor antagonist to inhibit glutamate mediated neurotoxicity as neurons die during AD progression [@Long2019-qm]. Memantine has been approved for moderate severe to severe AD, however the drug has not been shown to slow the progression of the disease or prove effective in mild-to-moderate stages of the disease [@Folch2018-vb; @Rogawski2003-od].

Two anti-amyloid human monoclonal immunotherapies, aducanumab and lecanemab, have recently been granted approval by the United States Food and Drug Administration (US FDA) [@Center_for_Drug_Evaluation2023-gy; @Office_of_the_Commissioner2023-hu]. Aducanumab approval was rejected by the European Medicines Agency (EMA) due to the conflicting phase III clinical trial evidence and concerns over patient safety [@Alexander2021-ln; @Mahase2021-no], whereas lecanumab is currently under review by the EMA for approval [@noauthor_undated-ml]. Aducanemab targets the soluble Aβ oligomers and insoluble fibrils whereas lecanumab targets the soluble Aβ protofibrils, but both led to the development of severe adverse events including amyloid-related imaging abnormalities (ARIA) [@Sevigny2016-yx; @Brenman2023-ki]. These results suggest further research is needed to understand the full molecular causes of AD to help find safe yet effective treatments.

Recent comprehensive reviews have identified a shift in research with more Phase I studies being conducted and four more anti-amyloid monoclonal antibody treatments having completing or currently undergoing Phase III clinical trials [@Cummings2023-lo; @Huang2023-vq]. These trials are involving more patients with early onset AD and mild cognitive impairment (MCI) to help develop preventative therapies. Global estimates for people living with preclinical AD or positive for AD pathology biomarkers were 69 and 315 million, respectively [@Gustavsson2023-qr], therefore increasing research focus on these patient populations is imperative to slow the progression of the disease. Clinical trials including disease modifying therapies targeting tau have also increased with most in phase I studies, therefore research may be shifting to the other pathological hypotheses of AD to identify treatments. These reviews have not been updated since the accelerated approval of lecanemab, therefore we aim to identify whether there is a transition in research topics.

## Text Mining and Topic Modelling in AD Research

Thousands of articles are published every year concerning AD, so focusing on early-stage drug discovery could lead to more literature and clinical findings being identified. Systematic reviews and meta-analyses however, are time consuming and labour intensive, and pose a significant challenge to updating the current understandings in the research literature [@Higgins2019-kn]. Topic modelling, a prominent text mining technique, can find patterns and relationships within natural language data, and could provide an automated and unbiased overview of research text. The most common topic modelling method is Latent Dirichlet Allocation (LDA) which assumes, for unstructured text data like research publication, that each document is made up of a number of topics and that each topic is made up of a collection of words [@Blei2003-lh]. Each LDA topic is represented as a probability of words within a topic and a probability of topics within each document, which each follow a Dirichlet distribution.

*In silico* topic modelling has been used for various applications relating to AD, including describing the research landscape [@Martinelli2022-ic], identifying novel biomarkers [@Greco2012-pv], and drug repurposing [@Nian2022-xw]. Martinelli [@Martinelli2022-ic] performed a nine-topic LDA model and identified five mechanistic themes, one topic relating to AD diagnosis and three concerning treatments. *Any publication relating to using LDA to update knowledge with a shift in the literature.* To the best of my knowledge, no studies have explored the change to the AD research landscape with the emergence of newly approved immunotherapy treatments.

## Aims and Hypotheses

Vast quantities of literature are being published annually concerning AD. We aim to comprehensively characterise AD research through the period that the AD immunotherapy drug, lecanemab, underwent accelerated approval for early AD on the 6th July 2023. We hypothesise that new treatments targeting the pathophysiological changes in patients with AD, represent a major paradigm shift in AD research. We propose that LDA topic models can help identify distinct thematic changes in the literature. We will identify whether theses methods can summarise the latest research are crucial for making significant strides in understanding the complexities of this disease and finding new ways to treat AD. Furthermore, this method could be translated to other neurodegenerative disease and to study the impact of emerging novel treatment options.

# Methods

A full summary of the methodology is provided in @fig-full-summary. All data analysis and visualisations were done in R version 4.3.2 using *tidyverse* packages [@Wickham2019-rj] unless otherwise stated.

::: {#fig-full-summary}
```{r}
#| label: fig-full-summary

knitr::include_graphics("data/methodsummary.png")

```

**Summary of Methods.** Abstracts gathered from PubMed then updated with *litsearchr* results, or from preprint databases were read into R. Meta data analysis was performed then text was tidied and tokenised, then allocated to two corpuses relative to the accelerated approval date of lecanemab. LDA topic modelling and n-gram analysis results were collected then interpreted.
:::

## Data Acquisition

Due to accessing constraints, abstracts represent the only document content for this study. Titles, full abstract text, and publication date were obtained from the National Center for Biotechnology Information (NCBI) datasbase, PubMed, using the inclusion criteria described in @tbl-inclusion-criteria, and accessed through *Rismed* [@Kovalchik2021-xq] on 18-02-2024. Results from PubMed were combined with publications from the preprint data sources, bioRxiv and medXriv, using *medrxiv* [@medrxivr]. An additional dataset was generated for abstracts containing the associated terminology for the AD drug lecanemab: '*lecanemab*', '*leqembi*' '*BAN2401*', and '*mAb158*'. The diversity of entries into the PubMed database ensures that the contents are representative and studies are reliable as they are obtained from multiple sources. Entries are assigned Medical Subject Headings (MeSH) which identify health-related terms within each document, therefore classifying articles according to their subject nature which reduces potential interpretive bias.

+----------------------------+------------------------------------------------+
| Criteria                   | Filter Applied                                 |
+============================+================================================+
| MeSH Term                  | 'Alzheimer's Disease'                          |
+----------------------------+------------------------------------------------+
| Title and/or Abstract Text | 'Alzheimer's Disease'                          |
|                            |                                                |
|                            | 'AD'                                           |
+----------------------------+------------------------------------------------+
| Article Type               | "Books"                                        |
|                            |                                                |
|                            | "Case Reports"                                 |
|                            |                                                |
|                            | "Clinical Study"                               |
|                            |                                                |
|                            | "Clinical Trial"                               |
|                            |                                                |
|                            | "Controlled Clinical Trial"                    |
|                            |                                                |
|                            | "Meta-analysis"                                |
|                            |                                                |
|                            | "Randomised Controlled Trial"                  |
|                            |                                                |
|                            | "Review"                                       |
|                            |                                                |
|                            | "Systematic Review"                            |
+----------------------------+------------------------------------------------+
| Publication Date           | 1st January 2022 to 1st January 2024 inclusive |
+----------------------------+------------------------------------------------+
| Language                   | English                                        |
+----------------------------+------------------------------------------------+

: **Inclusion criteria used to query and identify all relevant terms concerning AD in the PubMed database.** Adapted from @Martinelli2022-ic. {#tbl-inclusion-criteria}

### *litsearchR*

To reassure us that the PubMed search query encapsulated all literature, *litsearchr* package was used to expand the search terms [@Grames2019-as]. Citations from PubMed results using the previous search criteria in @tbl-inclusion-criteria were read into R. The combined unique keyword and titles, as not all articles have keywords, for each result were collected. To ensure only the most relevant terms were searched, stop words were removed, as previously described, and the minimum frequency of words for keywords and title was set to n = 50 and n = 75, respectively. A matrix of each word in each article was created and the potential search terms were ranked with *create_network* and *strength* [@Barrat2004-hm] from the *igraph* package [@Csardi2006-gb]. The change point method calculated the optimal cutoff positions based on the trend in sharp changes for *strength*.

```{r}
#| label: search-terms
#| include: false
#| cache: true

naive_results <- import_results(file="data/pubmed-alzheimerd-set.nbib")
naive_drug_results <- import_results(file="data/pubmed-lecanemabO-set.nbib")

nrow(naive_results)

keywords <- extract_terms(keywords=naive_results[, "keywords"], 
                          method="tagged", 
                          min_n = 1, # allows single words
                          min_freq = 50) # only words that appear at least 10 times in keyword search 

# Remove stop-words from titles
clin_stopwords <- read_lines("data/clin_stopwords.txt")
all_stopwords <- c(get_stopwords("English"), clin_stopwords)

title_terms <- extract_terms(
  text = naive_results[, "title"],
  method = "fakerake",
  min_freq = 75, 
  min_n = 1,
  stopwords = all_stopwords
)

search_terms <- c(keywords, title_terms) %>% unique()


### Network analysis ###

# Combine title with abstract
docs <- paste(naive_results[, "title"], naive_results[, "abstract"])

# Create matrix of which term appears in which article
dfm <- create_dfm(elements = docs, 
                  features = search_terms)

# Create network of linked terms
g <- create_network(dfm, 
                    min_studies = 3)
ggraph(g, layout="stress") +
  coord_fixed() +
  expand_limits(x=c(-3, 3)) +
  geom_edge_link(aes(alpha=weight)) +
  geom_node_point(shape="circle filled", fill="white") +
  geom_node_text(aes(label=name), 
                 hjust="outward", 
                 check_overlap=TRUE) 

## Pruning ##

# Remove terms that are not connected to other terms - strength
strengths <- strength(g)

term_strengths <- data.frame(term=names(strengths), strength=strengths, row.names=NULL) %>%
  mutate(rank = rank(strength, 
                   ties.method="min")) %>%
  arrange(strength)

# Visualise to determine cutoff
cutoff_fig <- ggplot(term_strengths, aes(x=rank, 
                                         y=strength, 
                                         label=term)) +
  geom_line() +
  geom_point() +
  geom_text(data=filter(term_strengths, rank>5), hjust="right", nudge_y=20, check_overlap=TRUE)

cutoff_fig

# Find 80% cutoff
cutoff_cum <- find_cutoff(g, 
                          method="cumulative", 
                          percent=0.8)

# Add to figure
cutoff_fig +
  geom_hline(yintercept = cutoff_cum, 
             linetype = "solid")

# Add cutoffs for changes
cutoff_change <- find_cutoff(g, 
                             method = "changepoint", 
                             knot_num = 3)

```

## Data Preprocessing

Abstracts and their metadata were categorised into two corpuses based on their publication date relative to the date of lecanemab’s accelerated early approval, `r format(as.Date(leca_approv), "%d-%m-%Y")` [@Office_of_the_Commissioner2023-hu]. Full abstract text was tokenised into single words using the *unnest_tokens* function of the *tidytext* package [@Silge2016-jf] (@fig-preprocess-1). The same function was used for tokenising to bigrams and trigrams, using n = 2 and n = 3 respectively. Stop words from the *tidytext* package [@Silge2016-jf] combined with the personalised words frequent to the unigram analysis, "*alzheimer's*" and "*ad*", were then removed (@fig-preprocess-2). To prevent the different spellings of the same phrase from being counted multiple times, similar bigrams and trigrams were mapped to the same variable. For example, ‘*amyloid β*, ‘*beta amyloid*’, and ‘*amyloid aβ*’ were all mapped to ‘*amyloid beta*’, and '*mild cognitive impairments*' and '*cognitive impairment mci*' were mapped to ‘*mild cognitive impairment*’. Additionally, for bigrams originating from trigrams, mapping to the first two terms was used or mapping to an acronym, for example '*central nervous*', '*system cns'* were mapped to '*cns*'.

::: {#fig-preprocess}
```{r}
#| label: fig-preprocess
#| include: true
#| fig-subcap: 
#|  - "Unigram Tokenisation."
#|  - "Removal of Stop Words."
#| fig-width: 20
#| fig-height: 15 
#| fig-align: center

knitr::include_graphics("data/preprocess1.png")
knitr::include_graphics("data/preprocess2.png")
```

**Abstract preprocessing into unigrams.** Schematic of an abstract being (A) tokenised into single-word tokens followed by (B) removal of stop words obtained from the *tidytext* package [@Silge2016-jf] and personalised words frequent to the unigram analysis, '*alzheimers*', and '*AD*'. Tokenisation and data cleaning of bigrams and trigrams followed the same methods, not shown.
:::

```{r}
#| label: bigram-cleaning
#| include: false
bigrams_separated <- abstract_bigrams %>%
  separate(bigram, c("word1", "word2"), sep = " ")
bigrams_separated <- bigrams_separated %>%
  filter(!word1 %in% stop_words$word &
         !word1 %in% my_stopwords$word) %>% # remove word1 if stopword
  filter(!word2 %in% stop_words$word &
         !word2 %in% my_stopwords$word) # remove word2 if stopword

# join word1 and word2 back together into bigram
bigrams_united <- bigrams_separated %>%
  unite(bigram, word1, word2, sep = " ")  # 'bigram' name of new column
  
## Map words and remove abbreviations ##
bigrams_united <- bigrams_united %>% 
 # filter(grepl("alzheimer*\\b*disease*", bigram)) %>% 
  mutate(bigram = str_replace_all(bigram, 
                              "\\b(neurodegenerative dis(?:ease|eases|order|orders)?)\\b|\\b(neurological dis(?:ease|eases|order|orders)?)\\b", 
                              "neurodegenerative disease"),
         bigram = str_replace_all(bigram,
                                  "\\b(central nervous)\\b|\\b(system cns)\\b",
                                  "central nervous"),
         bigram = str_replace_all(bigram,
                                  "\\b(parkinson's disease)\\b|\\b(disease pd)\\b|\\b(parkinson's diseases)\\b|\\b(parkinson's pd)\\b|\\b(parkinson disease)\\b|\\b(disease parkinson's)\\b",
                                  "parkinson's disease"),
         bigram = str_replace_all(bigram,
                                  "\\b(huntington's disease)\\b|\\b(disease hd)\\b|\\b(huntington's diseases)\\b|\\b(huntingon's hd)\\b|\\b(huntington disease)\\b|\\b(disease huntington's)\\b",
                                  "huntington's disease"),
         bigram = str_replace_all(bigram,
                                  "\\b(blood brain)\\b|\\b(brain barrier)\\b",
                                  "blood brain"),
         bigram = str_replace_all(bigram,
                                  "\\b(amyloid\\s*\\p{Greek})\\b|\\b(amyloid beta)\\b|\\b(beta amyloid)\\b|\\b(β aβ)\\b|\\b(amyloid β)\\b|\\b(beta aβ)\\b",
                                   "amyloid beta"),
         bigram = str_replace_all(bigram,
                                  "\\b(2019 covid)\\b|\\b(covid 19)\\b|\\b(sars cov)\\b|\\b(cov 2)\\b",
                                  "covid 19"),
         bigram = str_replace_all(bigram,
                                  "\\b(2 diabetes)\\b|\\b(diabetes t2d)\\b|\\b(type 2)\\b",
                                  "diabetes t2d"),
         bigram = str_replace_all(bigram,
                                  "\\b(amyotrophic lateral)\\b|\\b(lateral sclerosis)\\b|\\b(disease amyotrophic)\\b|\\b(sclerosis als)\\b",
                                  "amyotrophic lateral"),
         bigram = str_replace_all(bigram,
                                   "\\b(α syn|α synuclein|alpha synuclein|alpha synucleinuclein)\\b",
                                  "alpha synuclein"),
         bigram = str_replace_all(bigram,
                                  "\\b(cerebrospinal fluid)\\b|\\b(fluid csf)\\b|\\b(cerebrospinal csf)\\b",
                                  "cerebrospinal fluid"),
         bigram = str_replace_all(bigram,
                                  "\\b(cardiovascular dis(?:ease|eases|order|orders)?)\\b",
                                  "cardiovascular disease"))

# All abstracts
bigram_counts <- bigrams_united %>% 
  group_by(type) %>% 
  count(bigram, sort = TRUE) %>% 
  ungroup()

```

```{r}
#| label: trigram clean
#| include: false
trigrams_separated <- abstract_trigrams %>%
  separate(trigram, c("word1", "word2", "word3"), sep = " ")
trigrams_separated <- trigrams_separated %>%
  filter(!word1 %in% stop_words$word &
           !word1 %in% my_stopwords$word) %>% # remove word1 if stopword
  filter(!word2 %in% stop_words$word &
           !word2 %in% my_stopwords$word) %>% # remove word2 if stopword
  filter(!word3 %in% stop_words$word &
           !word3 %in% my_stopwords$word) # remove word3 if stopword

trigrams_united <- trigrams_separated %>%
  group_by(type) %>% 
  unite(trigram, word1, word2, word3, sep = " ") %>%  # 'trigram' name of new column
  ungroup()

trigrams_united <- trigrams_united %>%
  mutate(trigram = str_replace_all(trigram, 
                                   "\\b(?:mild cognitive impairment|cognitive impairment mci)\\b", 
                                   "mild cognitive impairment"),
         trigram = str_replace_all(trigram,
                                   "\\b(?:central nervous system|nervous system cns|central nervous system)\\b", 
                                   "central nervous system"),
         trigram = str_replace_all(trigram,
                                   "\\b(?:blood brain barrier|brain barrier bbb)\\b", 
                                   "blood-brain barrier"),
         trigram = str_replace_all(trigram,
                                   "\\b(?:amyotrophic lateral sclerosis|lateral sclerosis als|amyotropic lateral sclerosis|disease amyotrophic lateral)\\b",
                                   "amyotrophic lateral sclerosis"),
         trigram = str_replace_all(trigram,
                                   "\\b(?:amyloid beta aβ|β amyloid aβ|amyloid β aβ|amyloid β peptide|amyloid β protein)\\b",
                                   "amyloid beta aβ"),
         trigram = str_replace_all(trigram,
                                   "\\b(?:type 2 diabetes|diabetes mellitus t2dm|2 diabetes mellitus)\\b", 
                                   "type 2 diabetes"),
         trigram = str_replace_all(trigram,
                                   "\\b(?:huntington's disease hd|disease huntington's disease|disease huntington disease|huntington disease hd|huntington's diseases hd)\\b",
                                   "huntington's disease hd"),
         trigram = str_replace_all(trigram,
                                   "\\b(?:parkinson's disease pd|disease parkinson's disease|disease parkinson disease|parkinson disease pd|parkinson's diseases pd)\\b",
                                   "parkinson's disease pd"),
         trigram = str_replace_all(trigram,
                                   "\\b(?:multiple sclerosis ms|disease multiple sclerosis)\\b",
                                   "multiple sclerosis ms"),
         trigram = str_replace_all(trigram,
                                   "\\b(amyloid precursor protein|precursor protein app)\\b",
                                   "amyloid precursor protein"),
         trigram = str_replace_all(trigram,
                                   "\\b(reactive oxygen species|oxygen species ros)\\b",
                                   "reactive oxygen species"),
         trigram = str_replace_all(trigram,
                                   "\\b(magnetic resonance imaging|resonance imaging mri)\\b",
                                   "magnetic resonance imaging"),
         trigram = str_replace_all(trigram,
                                   "\\b(randomized controlled trial|randomized controlled trials|randomized clinical trials|randomized clinical trial|randomised controlled trials|randomised controlled trial|controlled trials rcts|controlled trial rct)\\b",
                                   "randomised controlled trials"),
         trigram = str_replace_all(trigram,
                                   "\\b(lewy body dementia|lewy bodies dlb|dementia lewy body)\\b",
                                   "lewy body dementia"))

trigram_counts <- trigrams_united %>% 
  group_by(type) %>%
  count(trigram, sort = TRUE) %>%
  ungroup()
```

## Data Analysis

### Metadata Analysis

The number of relevant abstracts published per month were visualised as well as the frequency of dates of publications for papers containing the associated terminology for the AD drug lecanemab were also obtained.

### Term Frequency

#### N-gram Frequency Analysis

After tokenisation, the top 20 most frequent unigrams were determined for each dataset. The top 20 most frequent bigrams and trigrams were also determined due to many unigrams being associated with pairs or triplets of words. For example, “mild cognitive impairment” relates to a neurological condition, whereas the words “mild”, “cognitive” and “impairment” have ambiguous connotations individually.

#### Term Usage Over Time

The distribution of terms used over 1000 times from the unigram analysis was visualised. Generalised linear model (GLM) was used to determine whether there was a significant change in word usage over the months.

```{r}
#| label: fig-glm-words
#| include: false

## Create Generalised linear model

top_words <- c("disease", "brain", "studies", "diseases", "review", "cognitive", "dementia", "neurodegenerative", "clinical", "patients", "treatment", "tau", "amyloid", "risk")

# Get word frequency per month
glm_abstracts <- abstract_unigrams_clean %>%  
  filter(word %in% top_words) %>% 
  mutate(date = floor_date(date, "month")) %>% # round date to month
  group_by(date) %>%
  count(word, sort = TRUE) %>%
  ungroup() %>%
  group_by(word) %>%
  mutate(freq = n / sum(n)) %>%
  ungroup() 

# for bigrmas
top_bigrams <- c("neurodegenerative disease", "parkinson's disease", "amyloid beta", "cognitive impairment", "als", "cns", "nervous system", "cognitive decline", "blood brain", "oxidative stress", "covid 19", "clinical trials", "meta analysis", "huntington's disease")

# Get word frequency per month
glm_abstracts_bigram <- bigrams_united %>%  
  filter(bigram %in% top_bigrams) %>% 
  mutate(date = floor_date(date, "month")) %>% # round date to month
  group_by(date) %>%
  count(bigram, sort = TRUE) %>%
  ungroup() %>%
  group_by(bigram) %>%
  mutate(freq = n / sum(n)) %>%
  ungroup()

# Generalised linear model
glm <- glm(freq ~ date + word, data = glm_abstracts, family = "poisson" )
summary(glm)

# Call:
# glm(formula = freq ~ date + word, family = "poisson", data = glm_abstracts)
# 
# Coefficients:
#                         Estimate Std. Error z value Pr(>|z|)
# (Intercept)           -8.767e+00  2.461e+01  -0.356    0.722
# date                   2.889e-04  1.271e-03   0.227    0.820
# wordbrain              8.887e-17  1.414e+00   0.000    1.000
# wordclinical           2.193e-16  1.414e+00   0.000    1.000
# wordcognitive          3.630e-16  1.414e+00   0.000    1.000
# worddementia           1.625e-17  1.414e+00   0.000    1.000
# worddisease            1.543e-15  1.414e+00   0.000    1.000
# worddiseases           1.325e-16  1.414e+00   0.000    1.000
# wordneurodegenerative  2.246e-16  1.414e+00   0.000    1.000
# wordpatients           6.562e-17  1.414e+00   0.000    1.000
# wordreview             7.887e-17  1.414e+00   0.000    1.000
# wordrisk               8.880e-17  1.414e+00   0.000    1.000
# wordstudies            1.883e-16  1.414e+00   0.000    1.000
# wordtau                7.248e-17  1.414e+00   0.000    1.000
# wordtreatment         -1.227e-17  1.414e+00   0.000    1.000
# 
# (Dispersion parameter for poisson family taken to be 1)
# 
#     Null deviance: 0.46242  on 335  degrees of freedom
# Residual deviance: 0.41069  on 321  degrees of freedom
# AIC: Inf
# 
# Number of Fisher Scoring iterations: 6
```

### Topic Modelling

A document term matrix (dtm) was constructed for each dataset, indicating each word’s term frequency (tf), which is a measure of how often a word appears in each abstract To determine if a statistical model could distinguish between the text corpuses surrounding the accelerated approval date of lecanemab, a two-topic Latent Dirich Allocation (LDA) model [@Blei2003-lh] was applied to the dtm using *topicmodels* [@Grun2011-do]. The per-document-per-topic probabilities (γ) was extracted to show the proportion of words generated in each topic and how often these words appear in either corpuses.

Two ten-topic LDA models were also created, one for each text corpuses, to determine the most frequent topics, where an arbitrary topic number (k) of ten was chosen. The per-topic-per-word probabilities (β) were extracted and the top 10 terms most common words found in each topic were visualised. In each model the abstracts are considered mixtures of topics and each topic is considered a mixture of words.

```{r}
#| label: Gamma LDA Topic Modelling
#| include: false
#| cache: true

# # Create document term matrix of bigrams
# bigram_dtm <- bigrams_separated %>%
#   unite(bigram, word1, word2, sep = " ") %>% 
#   count(abstract, bigram) %>% 
#   cast_dtm(abstract, bigram, n)

unigram_dtm <- abstract_unigrams_clean %>%
  count(abstract, word) %>% 
  cast_dtm(abstract, word, n)

# Create 2 topic LDA model for all abstracts
all_lda <- LDA(unigram_dtm, k = 2, control = list(seed = 1234))

# Get gamma scores
tidy_lda_gamma <- tidy(all_lda, 
                 matrix = "gamma")

# Join results with abstract to get the date variable
abstract_gamm <- tidy_lda_gamma %>%
  mutate(abstract = as.numeric(document)) %>% 
  left_join(abstract_unigrams_clean, by = "abstract") %>% 
  select(document, gamma, topic, date) %>% 
  mutate(type = case_when(date <= leca_approv ~ "pre-leca",
                          date > leca_approv ~ "post-leca"))

## See if significant difference
wilcox.test(abstract_gamm$gamma)

# Wilcoxon signed rank test with continuity correction
# 
# data:  abstract_gamm$gamma
# V = 1.3843e+12, p-value < 2.2e-16
# alternative hypothesis: true location is not equal to 0
```

```{r}
#| label: LDA Topic Model Bigrams
#| include: false
#| cache: true

# Cast the bigram counts into a document term matrix
bigram_dtm_pre <- bigrams_united %>%
  filter(type == "pre-leca") %>% 
  count(abstract, bigram) %>% 
  cast_dtm(abstract, bigram, n) 

bigram_dtm_post <- bigrams_united %>%
  filter(type == "post-leca") %>% 
  count(abstract, bigram) %>% 
  cast_dtm(abstract, bigram, n)

bigram_lda_pre <- LDA(bigram_dtm_pre, k = 10, control = list(seed = 1234))
# A LDA_VEM topic model with 10 topics
bigram_lda_post <- LDA(bigram_dtm_post, k = 10, control = list(seed = 1234))
# A LDA_VEM topic model with 10 topics.

# Interpret the model
tidy_bigram_lda_pre <- tidy(bigram_lda_pre, 
                            matrix = "beta")

tidy_bigram_lda_post <- tidy(bigram_lda_post,
                             matrix = "beta")

# Top 10 terms per topic
#   Not including 'neurodegenerative diseases', parkinson\'s disease' and 'cognitive impairment' as these were common to all bar one topics

top_bigram_terms_pre <- tidy_bigram_lda_pre %>%
  filter(!term %in% c("neurodegenerative disease", "parkinson\'s disease", "amyloid beta")) %>%
  # mutate(topic = case_when(topic == 1 ~ "Mechanisms",
  #                          topic == 2 ~ "Protein",
  #                          topic == 3 ~ "Something else1",
  #                          topic == 4 ~ "Something else2",
  #                          topic == 5 ~ "Something else3",
  #                          topic == 6 ~ "Something else4",
  #                          topic == 7 ~ "Something else5",
  #                          topic == 8 ~ "Something else6",
  #                          topic == 9 ~ "Something other",
  #                          topic == 10 ~ "Something else7")) %>% 
  group_by(topic) %>%
  slice_max(beta, n = 10, with_ties = FALSE) %>%
  ungroup() %>%
  arrange(topic, -beta)

top_bigram_terms_post <- tidy_bigram_lda_post %>%
  filter(!term %in% c("neurodegenerative disease", "parkinson\'s disease")) %>%
  # mutate(topic = case_when(topic == 1 ~ "Mechanisms",
  #                          topic == 2 ~ "Protein",
  #                          topic == 3 ~ "Something else1",
  #                          topic == 4 ~ "Something else2",
  #                          topic == 5 ~ "Something else3",
  #                          topic == 6 ~ "Something else4",
  #                          topic == 7 ~ "Something else5",
  #                          topic == 8 ~ "Something else6",
  #                          topic == 9 ~ "Something other",
  #                          topic == 10 ~ "Something else7")) %>% 
  group_by(topic) %>%
  slice_max(beta, n = 10, with_ties = FALSE) %>%
  ungroup() %>%
  arrange(topic, -beta)

# Visualise
top_bigram_terms_pre <- top_bigram_terms_pre %>%
  mutate(term = reorder_within(term, beta, topic)) %>%
  group_by(topic, term) %>%    
  arrange(desc(beta)) %>%  
  ungroup() %>%
  ggplot(aes(beta, term, fill = as.factor(topic))) +
  geom_col(show.legend = FALSE) +
  scale_y_reordered() +
  labs(title = "Top 10 bigrams in each LDA topic: Pre-leca",
       x = expression(beta), y = NULL) +
  facet_wrap(~ topic, ncol = 4, scales = "free")


top_bigram_terms_post <- top_bigram_terms_post %>%
  mutate(term = reorder_within(term, beta, topic)) %>%
  group_by(topic, term) %>%    
  arrange(desc(beta)) %>%  
  ungroup() %>%
  ggplot(aes(beta, term, fill = as.factor(topic))) +
  geom_col(show.legend = FALSE) +
  scale_y_reordered() +
  labs(title = "Top 10 bigrams in each LDA topic: Post-leca",
       x = expression(beta), y = NULL) +
  facet_wrap(~ topic, ncol = 4, scales = "free")
```

```{r}
#| label: LDA Topic Model Trigrams
#| include: false
#| cache: true

# Cast the bigram counts into a document term matrix
trigram_dtm_pre <- trigrams_united %>%
  filter(type == "pre-leca") %>% 
  count(abstract, trigram) %>% 
  cast_dtm(abstract, trigram, n) 

trigram_dtm_post <- trigrams_united %>%
  filter(type == "post-leca") %>% 
  count(abstract, trigram) %>% 
  cast_dtm(abstract, trigram, n)

trigram_lda_pre <- LDA(trigram_dtm_pre, k = 10, control = list(seed = 1234))
# A LDA_VEM topic model with 10 topics
trigram_lda_post <- LDA(trigram_dtm_post, k = 10, control = list(seed = 1234))
# A LDA_VEM topic model with 10 topics.

# Interpret the model
tidy_trigram_lda_pre <- tidy(trigram_lda_pre, 
                            matrix = "beta")

tidy_trigram_lda_post <- tidy(trigram_lda_post,
                             matrix = "beta")

# Top 10 terms per topic
#   Not including 'neurodegenerative diseases', parkinson\'s disease' and 'cognitive impairment' as these were common to all bar one topics

top_trigram_terms_pre <- tidy_trigram_lda_pre %>%
  filter(!term %in% c("central nervous system", "parkinson's disease pd", "blood-brain barrier")) %>%
    # mutate(topic = case_when(topic == 1 ~ "Mechanisms",
    #                        topic == 2 ~ "Protein",
    #                        topic == 3 ~ "Something else1",
    #                        topic == 4 ~ "Something else2",
    #                        topic == 5 ~ "Something else3",
    #                        topic == 6 ~ "Something else4",
    #                        topic == 7 ~ "Something else5",
    #                        topic == 8 ~ "Something else6",
    #                        topic == 9 ~ "Something other",
    #                        topic == 10 ~ "Something else7")) %>% 
  group_by(topic) %>%
  slice_max(beta, n = 10, with_ties = FALSE) %>%
  ungroup() %>%
  arrange(topic, -beta)

top_trigram_terms_post <- tidy_trigram_lda_post %>% 
  filter(!term %in% c("central nervous system", "parkinson's disease pd")) %>%
  # mutate(topic = case_when(topic == 1 ~ "Mechanisms",
  #                          topic == 2 ~ "Protein",
  #                          topic == 3 ~ "Something else1",
  #                          topic == 4 ~ "Something else2",
  #                          topic == 5 ~ "Something else3",
  #                          topic == 6 ~ "Something else4",
  #                          topic == 7 ~ "Something else5",
  #                          topic == 8 ~ "Something else6",
  #                          topic == 9 ~ "Something other",
  #                          topic == 10 ~ "Something else7")) %>% 
  group_by(topic) %>%
  slice_max(beta, n = 10, with_ties = FALSE) %>%
  ungroup() %>%
  arrange(topic, -beta)


# Visualise
top_trigram_terms_pre <- top_trigram_terms_pre %>%
  mutate(term = reorder_within(term, beta, topic)) %>%
  group_by(topic, term) %>%    
  arrange(desc(beta)) %>%  
  ungroup() %>%
  ggplot(aes(beta, term, fill = as.factor(topic))) +
  geom_col(show.legend = FALSE) +
  scale_y_reordered() +
  theme(axis.text.y = element_text(size = 8)) +
  labs(title = "Top 10 trigrams in each LDA topic: Pre-leca",
       x = expression(beta), y = NULL) +
  facet_wrap(~ topic, ncol = 4, scales = "free")


top_trigram_terms_post <- top_trigram_terms_post %>%
  mutate(term = reorder_within(term, beta, topic)) %>%
  group_by(topic, term) %>%    
  arrange(desc(beta)) %>%  
  ungroup() %>%
  ggplot(aes(beta, term, fill = as.factor(topic))) +
  geom_col(show.legend = FALSE) +
  scale_y_reordered() +
  theme(axis.text.y = element_text(size = 8)) +
  labs(title = "Top 10 trigrams in each LDA topic: Post-leca",
       x = expression(beta), y = NULL) +
  facet_wrap(~ topic, ncol = 4, scales = "free")
```

# Results and Discussion

A full summary of the results is found in @fig-results-summary.

::: {#fig-results-summary}
```{r}
#| label: fig-results-summary
#| include: true
#| fig-width: 20
#| fig-height: 10
#| fig-align: centre

knitr::include_graphics("data/resultsummary.png")

```

**Summary of Results**
:::

## Search Query Refinement Identified the Term 'alzheimer'

Out initial search query was refined using *litsearchr* [@Grames2019-as] to determine the most important terms to the articles ranked by their strength (@fig-ad-search-terms). We disregarded '*alzheimer's disease*' as this MeSH term was included in the original search query, but we updated the PubMed search query with '*alzheimer*' (@tbl-inclusion-criteria). We omitted the unigram '*disease*' as it was too broad and may have encapsulated articles concerning other irrelevant neurodegenerative diseases into our query.

Due to our search strategy, a lot of papers contain the MeSH term 'Alzheimer's disease' may have been mentioned as a collective with other neurodegenerative diseases. MeSH terms are added manually to articles in PubMed, therefore there could also be a bias when authors add these to their publications. We tried to avoid this by filtering the titles and abstracts of PubMed articles to also contain the term '*alzheimer's disease*', '*ad*' or '*alzheimer*'. Similarly when MeSH terms were not available for the bioRxiv and medRxv databases, we used a similar search strategy to filter titles and abstract text to contain the term '*alzheimer's disease*' or '*alzheimer*', or '*ad*' and '*alzheimer's disease*'. Whilst this filtering would have biased our dataset as abstracts not containing these search terms were ommitted, we were still able to gain a large dataset of `r abstract_n` abstracts that were published between `r format(min(abstract_unigrams_clean$date), "%d-%m-%Y")` and `r format(max(abstract_unigrams_clean$date), "%d-%m-%Y")`.

::: {#fig-ad-search-terms}
```{r}
#| label: fig-ad-search-terms
#| include: true
#| fig-width: 15
#| fig-height: 10
#| fig-align: left

cutoff_fig +
  geom_hline(yintercept = cutoff_change, 
             linetype="dashed") +
  xlab("Rank") +
  ylab("Strength") +
  theme(legend.position = "none",
        axis.title.x = element_text(size = 20),
        axis.title.y = element_text(size = 20),
        axis.text.x = element_text(size = 15),
        axis.text.y = element_text(size = 15),
        axis.ticks = element_line(size = 1),
        panel.background = element_blank(),
        axis.line = element_line(colour = "black",
                                 size = 1)
        )

```

**Search query refinement using *litsearchr* identified '*alzheimer*'.** A matrix of each word in each article was created and the potential search terms were ranked with *create_network* and *strength* [@Barrat2004-hm] from the *igraph* package [@Csardi2006-gb]. The top keywords and words from the titles of AD papers, with minimum frequencies of n = 50 and n = 75, respectively, were ranked by their importance to article content. The dashed lines mark optimal cutoff positions where the trend in strength shows sharp changes.
:::

## AD Research Publication Frequency is not Associated with Lecanemab Approval

Lecanemab received accelerated and traditional approval in 2023 [@Office_of_the_Commissioner2023-hu; @Office_of_the_Commissioner2023-ka], however we did not find any variability in the overall frequency of literature published containing the MeSH term '*Alzheimer's Disease*' @fig-publication-date-1. Despite the frequency of publications containing the terms associated with the AD drug lecanemab exponentially increasing in 2023 (@fig-publication-date-2), there was no significant difference between the per-document-per-topic probabilities (γ) for the two-topic LDA models (@fig-gamma-lda). This suggests that the content of the abstracts did not change significantly after the accelerated approval of lecanemab.

::: {#fig-publication-date}
```{r}
#| label: fig-publication-date
#| include: true
#| fig-subcap: 
#|  - "All Abstracts"
#|  - "Lecanemab Abstracts"
#| fig-width: 15
#| fig-height: 10
#| fig-align: left

abstract_unigrams_clean %>%  
  ggplot(aes(date)) +
  geom_histogram(bins = 100) +
  xlab("Date of Publication") +
  ylab("Number of Abstracts") +
  scale_x_date(date_breaks = "4 months", 
               date_labels = "%d/%m/%Y") +
  theme_classic() +
  theme(axis.text.x = element_text(angle = 45, 
                                   vjust = 0.5, 
                                   hjust = 0.5,
                                   size = 15),
        axis.title.x = element_text(size = 20),
        axis.title.y = element_text(size = 20),
        strip.text = element_text(size = 20),
        axis.text.y = element_text(size = 15),
        axis.ticks = element_line(size = 1),
        panel.background = element_blank(),
        axis.line = element_line(colour = "black",
                                 size = 1))  +
  geom_vline(xintercept = as.numeric(as.Date("2023-01-06")), 
             linetype = "dashed", 
             color = "red", 
             linewidth = 1)

## Visualise abstracts published with all lena terms
naive_drug_results %>% 
  filter(!is.na(date_published)) %>% 
  ggplot(aes(as.Date(date_published, format = "%Y %b %d"))) +
  geom_histogram(bins = 30,
                 binwidth = 100) +
  xlab("Date of Publication") +
  ylab("Number of Abstracts") +
  scale_x_date(date_breaks = "6 months", date_labels = "%m/%Y") +
  theme_classic() +
  theme(axis.text.x = element_text(angle = 45, 
                                   vjust = 0.5, 
                                   hjust = 0.5,
                                   size = 15),
        axis.title.x = element_text(size = 20),
        axis.title.y = element_text(size = 20),
        strip.text = element_text(size = 20),
        axis.text.y = element_text(size = 15),
        axis.ticks = element_line(size = 1),
        panel.background = element_blank(),
        axis.line = element_line(colour = "black",
                                 size = 1)
        ) +
  geom_vline(xintercept = as.numeric(as.Date("2023-01-06")), 
             linetype = "dashed", 
             color = "red", 
             linewidth = 1)
```

**Frequency of lecanemab publications increases in 2023.** Distribution of articles published over time containing (A) the MeSH term ‘Alzheimer’s Disease’ in the title and/or abstract (n = `r abstract_n`) or (B) terms associated with the AD drug lecanemab: ‘*lecanemab*’, ‘*leqembi*’, ‘*BAN2401*’, and ‘*mAb158*’ (n = 207). Dashed-line represents date of lecanemab accelerated approval, `r format(as.Date(leca_approv), "%d-%m-%Y")`.
:::

One reason for there not being any statistical significance between the per-document-per-topic probabilities could be due to the two-year time period being too short to account for a change in the research landscape as previous studies have used a five-year time period to characterise topics in AD literature [@Martinelli2022-ic]. This suggests that the topics in the period after the accelerated approval of lecanemab were not different to the topics in the year before lecanemab was approved. We found 3,468 abstracts published before and 3,276 abstracts published after the accelerated approval of lecanemab which is one of the largest per-year abstract corpuses concerning AD. Further research should explore a larger time period after the accelerated approval to conclude whether a change in the research literature can be found using topic models. This would suggest that our one-year analysis was too short as changes in AD research are slow and takes multiple years.

::: {#fig-gamma-lda}
```{r}
#| label: fig-gamma-lda
#| fig-width: 15
#| fig-height: 10
#| fig-align: left

abstract_gamm %>% 
  distinct(document, gamma, topic, date, type) %>%
  ggplot() +
  geom_boxplot(aes(x = type, y = gamma, fill = type),
               alpha = 3)  +
  facet_wrap(~ topic,
             strip.position = "bottom") +
  labs(y = expression(gamma)) +
  xlab("Topic") +
  theme(axis.title.x = element_text(size = 20),
        axis.title.y = element_text(size = 20),
        strip.text = element_text(size = 20),
        strip.text.x = element_text(size = 15),
        axis.text.x = element_blank(),
        axis.text.y = element_text(size = 15),
        legend.position = "right",
        legend.title = element_text(size = 20),
        legend.text = element_text(size = 15),
        panel.background = element_blank(),
        axis.line = element_line(colour = "black",
                                 size = 1),
        axis.ticks = element_blank(),
        strip.background = element_rect(color="black", 
                                        fill="white", 
                                        size=1, 
                                        linetype="solid")
     ) +
  scale_fill_manual(values = c("darkgray", "black"),
                    name = "Corpus Type",
                    limits = c("pre-leca", "post-leca"),
                    labels = c("Pre-Lecanemab\n Accelerated Approval", "Post-Lecanemab\n Accelerated Approval")) +
  scale_x_discrete(limits = c("pre-leca", "post-leca")) 
```

**Two topic LDA model does not distinguish change in literature around accelerated approval date of Lecanemab**. A document term matrix (dtm) was constructed for the unigram dataset and a two topic LDA model was applied to the dtm using *topicmodels* [@Grun2011-do]. Boxplots show first and third quartiles, median and outlier per-document-per-topic probabilities, γ. Corpus type was determined based on accelerated approval date for lecanemab, `r format(as.Date(leca_approv), "%d-%m-%Y")`. n = `r abstract_n`.
:::

Despite the full abstract dataset not significantly splitting into two distinct topics, we aimed to suggest this was because the language was very similar between the two corpses. We therefore aimed to explore the most common n-grams frequencies. '*Disease*' was the most frequent unigram in both corpuses (@fig-tokenisation-1) and was included with '*neurodegenerative disease*', '*Parkinson's disease*', and '*Huntington's disease*' which were among the most frequent bigrams and trigrams (@fig-tokenisation-2; @fig-tokenisation-3). Fourteen of the top fifteen most common unigrams were shared between the two corpuses, however there were no significant differences between the unigram frequencies over time (@fig-tokenisation-4). Similarly, fourteen of top fifteen bigrams and trigrams were shared between the two corpuses. This suggests that the word usage has remained consistent and indicating that the introduction of a novel anti-amyloid therapy may not have changed the research landscape during the observed period.

::: {#fig-tokenisation}
```{r}
#| label: fig-tokenisation
#| include: true
#| fig-subcap: 
#|  - "Unigram"
#|  - "Bigram"
#|  - "Trigram"
#|  - "Most common words"
#| fig-width: 15
#| fig-height: 10
#| fig-align: left

abstract_unigrams_clean %>% 
  group_by(type) %>%
  count(word, sort = TRUE) %>%
  slice_head(n = 15) %>% 
  ggplot(aes(n, reorder(word, n), fill = type)) +
  geom_col() +
  labs(y = NULL) +
  xlab("Count") +
  theme(axis.title.x = element_text(size = 20),
        axis.title.y = element_text(size = 20),
        strip.text = element_text(size = 20),
        axis.text.x = element_text(size = 15),
        axis.text.y = element_text(size = 15),
        axis.ticks = element_line(size = 1),
        panel.background = element_blank(),
        legend.position = "none",
        axis.line = element_line(colour = "black",
                                 size = 1),
        strip.background = element_rect(color="black", 
                                        fill="white", 
                                        size=1, 
                                        linetype="solid")) +
  facet_wrap(~factor(type, 
                     levels=c('pre-leca','post-leca'), 
                     labels = c("Pre-Lecanemab\n Accelerated Approval", "Post-Lecanemab\n Accelerated Approval")), 
              scale = "free") +
  scale_fill_manual(values = c("black", "darkgrey"))

bigram_counts %>% 
  filter(bigram != "alzheimers disease") %>% 
  group_by(type) %>%
  slice_head(n = 15) %>% 
  ggplot(aes(n, reorder(bigram, n), fill = type)) +
  geom_col() +
  labs(y = NULL) +
  xlab("Count") +
  theme(axis.title.x = element_text(size = 20),
        axis.title.y = element_text(size = 20),
        strip.text = element_text(size = 20),
        axis.text.x = element_text(size = 15),
        axis.text.y = element_text(size = 15),
        axis.ticks = element_line(size = 1),
        panel.background = element_blank(),
        legend.position = "none",
        axis.line = element_line(colour = "black",
                                 size = 1),
        strip.background = element_rect(color="black", 
                                        fill="white", 
                                        size=1, 
                                        linetype="solid")) +
  facet_wrap(~factor(type, 
                     levels=c('pre-leca','post-leca'), 
                     labels = c("Pre-Lecanemab\n Accelerated Approval", "Post-Lecanemab\n Accelerated Approval")), 
              scale = "free") +
  scale_fill_manual(values = c("black", "darkgrey"))

trigram_counts %>%
  group_by(type) %>%
  slice_head(n = 15) %>%
  ggplot(aes(x = n, y = reorder(trigram, n), fill = type)) +
  geom_col() +
  labs(y = NULL) +
  xlab("Count") +
  theme(axis.title.x = element_text(size = 20),
        axis.title.y = element_text(size = 20),
        strip.text = element_text(size = 20),
        axis.text.x = element_text(size = 15),
        axis.text.y = element_text(size = 15),
        axis.ticks = element_line(size = 1),
        panel.background = element_blank(),
        legend.position = "none",
        axis.line = element_line(colour = "black",
                                 size = 1),
        strip.background = element_rect(color="black", 
                                        fill="white", 
                                        size=1, 
                                        linetype="solid")) +
  facet_wrap(~factor(type, 
                     levels=c('pre-leca','post-leca'), 
                     labels = c("Pre-Lecanemab\n Accelerated Approval", "Post-Lecanemab\n Accelerated Approval")), 
              scale = "free") +
  scale_fill_manual(values = c("black", "darkgrey"))

glm_abstracts %>% ggplot(aes(x = date, y = freq)) +
  geom_line(aes(color = word),
            linewidth = 1) +
  ylab("Word Frequency") +
  xlab("Month of Publication") +
  scale_x_date(date_breaks = "6 months", date_labels = "%m/%Y") +
  theme(axis.text.x = element_text(angle = 45, 
                                   vjust = 0.5, 
                                   hjust = 0.5,
                                   size = 15),
        axis.title.y = element_text(size = 20),
        axis.title.x = element_text(size = 20),
        strip.text = element_text(size = 20),
        axis.text.y = element_text(size = 15),
        axis.ticks = element_line(size = 1),
        panel.background = element_blank(),
        legend.position = "right",
        axis.line = element_line(colour = "black",
                                 size = 1)
) +
  scale_color_manual(values = c("lightblue1", "cyan2", "darkgreen", "darkcyan", "deepskyblue", "cornflowerblue", "blue", "darkblue", "darkmagenta", "midnightblue", "purple", "plum1", "green", "purple4"),
                     name = "Unigram") +
    geom_vline(xintercept = as.numeric(as.Date("2023-01-06")), 
             linetype = "dashed", 
             color = "red", 
             linewidth = 1) 
```

**Literature use is similar around the time of lecanemab approval.** Corpus type was determined based on accelerated approval date for lecanemab, `r format(as.Date(leca_approv), "%d-%m-%Y")` then tokenised and removal of stop words. The 15 most frequent (A) unigrams, (B) bigrams and (C) trigrams along with (D) the distribution by month of the top 14 shared most frequent unigrams for both corpuses (n = `r abstract_n`). Dashed-line represents the accelerated approval date of lecanemab, `r format(as.Date(leca_approv), "%d-%m-%Y")`.
:::

### Research concerning genetic risk and molecular pathology were prominent before lecanemab underwent accelerated approval

The n-gram analysis suggested that term usage has not changed around the accelerated approval of lecanemab, so we used LDA topic modelling to see whether the terms may be distributed differently in topics in each corpus. In the year before the accelerated approval of lecanemab, we found ten topics with the top ten keywords (@fig-topic-model-unigrams-1). The first topic concerned genetics, specifically mentioning 'genes' and 'genetic' as well as 'covid' and '19' as genetic links have been hypothesised between having COVID-19 and developing AD [@Matveeva2023-nz; @Baranova2023-ba]. Multiple topics referenced study terminology, either relating to pre-clinical drug discovery in 'cells' and 'models' or clinical studies such as 'trials', 'human' which could be related to the increase in clinical trials [@Huang2023-vq]. As the cause of AD is not full understood, topics concerning the molecular pathology, specifically referencing the 'amyloid-beta' and 'tau', were identified which highlight the importance of these hypotheses. Topics concerning cellular pathology such as 'migroglia' and 'mitochondria' may be referring to the increased neuroinflammation relating to AD and recruitment of immune cells, as well as oxidative stress from neuronal death (@ref). Imaging techniques such as 'pet' and diagnostic markers from cerebrospinal fluid (CSF) represented another topic. Finally topics relating to brain function and neurodegeneration

Like previously found, topics concerning study treatments including ... What were terms in martinelli \[@Martinelli2022-ic\].

### Research concerning genetic risk and molecular pathology were prominent before lecanemab underwent accelerated approval

n the year before the accelerated approval of lecanemab, we found ten topics with the top ten keywords (@fig-topic-model-unigrams-2).

The topics *'Treatments'*, *'AD Diagnosis'*, *'Genetic Risk'*, *'Molecular Pathology'*, '*Study Terminology'* and *'Cellular Pathology'* were observed in abstracts before and after the accelerated approval of lecanemab @fig-topic-model-unigrams.

::: {#fig-topic-model-unigrams}
```{r}
#| label: fig-topic-model-unigrams 
#| include: true 
#| fig-subcap: 
#|   - "Pre-Lecenamab Accelerated Approval: Top 10 unigrams in each LDA topic" 
#|   - "Post-Lecanemab Accelerated Approval: Top 10 unigrams in each LDA topic" 
#| fig-width: 20
#| fig-height: 15 
#| fig-align: center

knitr::include_graphics("plots/pre-leca-lda-grey.png")
knitr::include_graphics("plots/post-leca-lda-blue2.png")
```

**Unigram LDA Topic Modelling.** Outputs from the ten-topic LDA model for abstracts published (A) before and (B) after the accelerated approval date of lecenamab, `r leca_approv`. The top 10 unigrams per topic are ordered by their per-topic-per-word probability, β. Topic titles were manually created and added. Colours are arbitory and match when the same topic was identified from (A) to (B), else are gray.
:::

### Tau research may be increasing after lecanemab accelerated approval.

Topics containing study terminology were common to both corpuses, however the unigram '*placebo*' was unique to the later corpus. This could suggest an increase in the number of randomised clinical trials (RCT) after lecanemab received accelerated approval as these trials usually involve a placebo-control. This is consistent with the trends observed in [@Huang2023-vq] which suggest an increase in Phase III clinical trials for anti-amyloid therapies and encompasses the traditonal approval date of lecanemab by the FDA in July 2023 from the Clarity AD clinical trial [@Office_of_the_Commissioner2023-ka]. Placebos are used when there is no known or FDA-approved therapy that can be tolerated by patients, therefore as AD does not have a standard of care treatment to cure the disease, a placebo may be used in RCTs.

We aimed to see whether there had been a change in the terms found in similar topics between the two corpuses. There was an increase in the beta-value for the terms in the '*Molecular Pathology'* topic after the accelerated approval of lecanemab, specifically for the terms: '*tau'*, '*amyloid',* and *'aβ'.* This suggests these unigrams were more associated with topics in the latter corpus.

The term '*insulin*' was not found in the later corpus @fig-topic-model-unigrams-2, however '*type 2 diabetes'* was one of the most common trigrams for both corpuses (@fig-tokenisation-3). AD has been referred to as type 3 diabetes due to the rapid growth of literature concerning brain insulin resistance and experimental evidence has shown insulin sensitiser treatments may help attenuate learning deficits [@De_la_Monte2008-uy; @Reger2008-xj; @Pedersen2006-pl; @Reger2006-nq]. Many epidemiological studies have suggested T2DM may be increasing the risk of AD, leading to the lower brain insulin levels resulting in decreased clearance of amyloid-beta [@Gasparini2001-up; @Ott1999-pv]. Despite this growing area of research, observations between non-demented participants and AD patients with T2DM have not been able to show a significant difference in amyloid accumulation [@Cholerton2016-iz]. Whilst we cannot conclude from our results whether this suggests a shift in research focusing on T2DM and its metabolic link to AD, we have observed that literature around the approval of lecanemab does concern multiple metabolic and immune changes relating to AD.

We found topics that contained general terms relating to neurodegenerative diseases and research in both text corpuses, however this may be due to us using only abstract text which only provides a summary of the larger article text. Further research should replicate our methodology using full article text to validate our results, however abstracts represent a concise summary of articles, so the main keywords should be included here. Despite this, some major topics may be lost by omitting the full article text.

```{r}
#| label: fig-beta-change
#| include: false
#| cache: true 
#| fig-width: 20
#| fig-height: 15 
#| fig-align: center

#::: {#fig-beta-change}

word_count_pre <- abstract_unigrams_clean %>%
  filter(type == "pre-leca") %>% 
  count(word, abstract, sort = TRUE) %>% 
  ungroup()

word_count_post <- abstract_unigrams_clean %>%
  filter(type == "post-leca") %>% 
  count(word, abstract, sort = TRUE) %>% 
  ungroup()

# Cast the word counts into a document term matrix
abstract_dtm_pre <- word_count_pre %>%
  cast_dtm(abstract, word, n) 

abstract_dtm_post <- word_count_post %>%
  cast_dtm(abstract, word, n)

# Running the LDA model
abstract_lda_pre <- LDA(abstract_dtm_pre, k = 10, control = list(seed = 1234))

abstract_lda_post <- LDA(abstract_dtm_post, k = 10, control = list(seed = 1234))

tidy_lda_pre <- tidy(abstract_lda_pre,
                     matrix = "beta") %>% 
  mutate(type = "pre_leca")
tidy_lda_post <- tidy(abstract_lda_post,
                      matrix = "beta") %>% 
  mutate(type = "post_leca")

top_terms_pre_topics <- tidy_lda_pre %>%
  filter(term != "disease" & term != "alzheimers") %>% 
  mutate(topic = case_when(topic == 1 ~ "Genetic Risk",
                           topic == 2 ~ "Drug Discovery",
                           topic == 3 ~ "Cellular Pathology",
                           topic == 4 ~ "Neurodegeneration",
                           topic == 5 ~ "Study Terminology",
                           topic == 6 ~ "Physical Health",
                           topic == 7 ~ "Brain Function",
                           topic == 8 ~ "Treatments",
                           topic == 9 ~ "AD Diagnosis",
                           topic == 10 ~ "Molecular Pathology")) %>%
  group_by(topic) %>%
  slice_max(beta, n = 10, with_ties = FALSE) %>%
  ungroup() %>%
  arrange(topic, -beta)

top_terms_post_topics <- tidy_lda_post %>%
  filter(term != "disease" & term != "alzheimers") %>% 
  mutate(topic = case_when(topic == 1 ~ "Treatments",
                           topic == 2 ~ "Epidemiology",
                           topic == 3 ~ "Research",
                           topic == 4 ~ "AD Diagnosis",
                           topic == 5 ~ "Publications",
                           topic == 6 ~ "Research",
                           topic == 7 ~ "Molecular Pathology",
                           topic == 8 ~ "Genetic Risk",
                           topic == 9 ~ "Clinical Studies",
                           topic == 10 ~ "Cellular Pathology")) %>%
  group_by(topic) %>%
  slice_max(beta, n = 10, with_ties = FALSE) %>%
  ungroup() %>%
  arrange(topic, -beta)

top_terms_post_topics %>% 
  rename(beta_post = beta) %>%
  left_join(top_terms_pre_topics %>% 
              rename(beta_pre = beta), by = c("term", "topic")) %>%
  mutate(beta_change = beta_post - beta_pre) %>% 
  filter(!is.na(beta_change)) %>%
  ggplot(aes(x = reorder(term, beta_change), y = beta_change, fill = as.factor(topic))) +
  geom_col(show.legend = FALSE) +
  facet_wrap(~ factor(topic,
                      levels = c("AD Diagnosis",
                                 "Cellular Pathology",
                                 "Genetic Risk",
                                 "Molecular Pathology",
                                 "Treatments"
                      )),                                    
                      ncol = 3, 
                      scales = "free") +
  scale_fill_manual(values = c("AD Diagnosis" ="purple", 
                               "Cellular Pathology" = "cyan2",
                               "Genetic Risk" = "darkmagenta", 
                               "Molecular Pathology" = "lightblue1", 
                               "Treatments" = "darkblue"
                               )) +
   theme(axis.title.x = element_text(size = 20),
        strip.text = element_text(size = 12),
        axis.text.x = element_text(size = 10),
        axis.text.y = element_text(size = 10),
        axis.ticks = element_line(size = 1),
        panel.background = element_blank(),
        axis.line = element_line(colour = "black",
                                 size = 1),
        strip.background = element_rect(color="black", 
                                        fill="white", 
                                        size = 1, 
                                        linetype="solid")) 
#Increase in beta values for tau and amyloid
#:::  
```

We only used abstracts written in English, so we may be missing abstracts that have not been translated from other languages and concern AD.

We only used abstracts!!! More information will be in the main text. Limited due to data collection strategies, therefore in the future should be able to mine more

Our suggest that the introduction of lecanemab has not had a significant impact on the research landscape of Alzheimer's disease in the years either side of its accelerated approval. Using text from abstracts of articles, we did not find any major changes using LDA topic modelling. While *in silico* methods of literature reviewing are useful to disseminate large quantities of text data, we would suggest they are not as robust as human input. We do however think that this automated approach could help provide an overview of major topics and increase the efficiency of understanding the large volume of studies in the AD literature. We hope this could help in the journey to find a cure for this devastating disease.

# Acknowledgements {.appendix}

I would like to thank my supervisor Emma Rand for her constant support and guidance throughout my project. I would also like to dedicate this project to my late granddad Alan Scrimshire who passed away on the 31st March 2023 after fighting a five year battle with Alzheimer’s Disease. I hope this project highlights the complexity of the disease and the vast efforts being undertaken to find a cure.

```{r}
#| label: fig-topic-model-bigrams
#| include: false
#| fig-cap: "**Bigram LDA Topic Modelling.** Outputs from the post-lecanemab (after 06/01/2023) corpus model with ten topics. Figures show the top ten most commonly associated bigrams in each topic ordered by their per-topic-per-word probability, β. Topic titles were manually created and added."
#| fig-subcap: 
#|  - "Pre-leca"
#|  - "Post-leca"
#| fig-width: 15
#| fig-height: 10
#| fig-align: left

# Pre-leca
top_bigram_terms_pre

top_bigram_terms_post
```

```{r}
#| label: fig-topic-model-trigrams
#| include: false
#| fig-cap: "**Trigram LDA Topic Modelling.** LDA model shows the top ten most commonly associated trigrams in each topic ordered by their per-topic-per-word probability, β, for (A) pre-leca and (B) post-leca corpuses. Topic titles were manually created and added."
#| fig-subcap: 
#|  - "Pre-leca"
#|  - "Post-leca"
#| fig-width: 15
#| fig-height: 10
#| fig-align: left

# Pre-leca
top_trigram_terms_pre

top_trigram_terms_post
```
